name: LLM RAG — Download Data, Ingest, Ask, Publish

on:
  workflow_dispatch:
    inputs:
      question:
        description: "Question to ask over the ingested docs"
        required: true
        default: "What is Retrieval-Augmented Generation and who introduced it?"
      top_k:
        description: "Top-k passages"
        required: true
        default: "5"
  schedule:
    - cron: "0 14 * * *"  # 9:00 AM America/Chicago daily

permissions:
  contents: write

jobs:
  run-rag:
    runs-on: ubuntu-latest
    env:
      STORE_DIR: store
      DATA_DIR: data
      QUESTION: ${{ github.event.inputs.question || 'What is Retrieval-Augmented Generation and who introduced it?' }}
      TOP_K: ${{ github.event.inputs.top_k || '5' }}
      USE_OPENAI: auto  # set "never" to always use fallback/no OpenAI calls

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest

      - name: Configure OpenAI (optional)
        env:
          OPENAI_API_KEY_SECRET: ${{ secrets.OPENAI_API_KEY }}
        run: |
          if [ -n "${OPENAI_API_KEY_SECRET}" ]; then
            echo "OPENAI_API_KEY=${OPENAI_API_KEY_SECRET}" >> "$GITHUB_ENV"
            echo "Using OpenAI if available (will fall back on error)."
          else
            echo "No OPENAI_API_KEY secret; using deterministic fallback."
          fi

      # Create the data downloader script (20 docs: 12 PDFs + 8 official guides as TXT)
      - name: Create download_data.sh
        run: |
          cat > download_data.sh <<'SH'
          #!/usr/bin/env bash
          set -euo pipefail

          ROOT="$(pwd)"
          DATA_DIR="${ROOT}/data"
          mkdir -p "${DATA_DIR}"

          have() { command -v "$1" >/dev/null 2>&1; }

          # Simple HTML -> TXT scrubber (uses lynx/w3m if present; otherwise sed fallback)
          html_to_txt() {
            in="$1"; out="$2"
            if have lynx; then
              lynx -dump -nolist "$in" > "$out"
            elif have w3m; then
              w3m -dump "$in" > "$out"
            else
              sed -E 's/<[[:space:]]*br[[:space:]]*\/?>/\n/Ig; s/<\/p>/\n\n/Ig; s/<[^>]+>//g' "$in" \
                | sed -E 's/[[:space:]]+/ /g; s/ *\n+/\n/g' > "$out"
            fi
          }

          get_pdf() {
            url="$1"; out="$2"
            echo "→ PDF: $out"
            curl -L --fail --retry 3 --retry-delay 2 "$url" -o "$out"
          }

          get_doc_as_txt() {
            url="$1"; out="$2"
            tmp="$(mktemp)"
            echo "→ DOC: $out (HTML→TXT)"
            curl -L --fail --retry 3 --retry-delay 2 "$url" -o "$tmp"
            html_to_txt "$tmp" "$out"
            rm -f "$tmp"
          }

          echo "== Downloading research PDFs (12) =="

          # 1) RAG (Lewis et al., 2020)
          get_pdf "https://arxiv.org/pdf/2005.11401" \
            "${DATA_DIR}/rag_lewis_2020.pdf"

          # 2) REALM (Guu et al., 2020)
          get_pdf "https://arxiv.org/pdf/2002.08909" \
            "${DATA_DIR}/realm_guu_2020.pdf"

          # 3) DPR (Karpukhin et al., 2020)
          get_pdf "https://arxiv.org/pdf/2004.04906" \
            "${DATA_DIR}/dpr_karpukhin_2020.pdf"

          # 4) ColBERT (Khattab & Zaharia, 2020)
          get_pdf "https://arxiv.org/pdf/2004.12832" \
            "${DATA_DIR}/colbert_khattab_2020.pdf"

          # 5) FiD (Izacard & Grave, 2020/21)
          get_pdf "https://arxiv.org/pdf/2007.01282" \
            "${DATA_DIR}/fid_izacard_grave_2020.pdf"

          # 6) RETRO (Borgeaud et al., 2021)
          get_pdf "https://arxiv.org/pdf/2112.04426" \
            "${DATA_DIR}/retro_borgeaud_2021.pdf"

          # 7) HyDE (Gao et al., 2022)
          get_pdf "https://arxiv.org/pdf/2212.10496" \
            "${DATA_DIR}/hyde_gao_2022.pdf"

          # 8) REPLUG (Shi et al., 2023)
          get_pdf "https://arxiv.org/pdf/2301.12652" \
            "${DATA_DIR}/replug_shi_2023.pdf"

          # 9) Self-RAG (Asai et al., 2023/ICLR 2024)
          get_pdf "https://arxiv.org/pdf/2310.11511" \
            "${DATA_DIR}/selfrag_asai_2023.pdf"

          # 10) Survey: Retrieval-Augmented Text Generation (Huang et al., 2024)
          get_pdf "https://arxiv.org/pdf/2312.10997" \
            "${DATA_DIR}/survey_rag_huang_2024.pdf"

          # 11) Survey: Evaluation of RAG (Yu et al., 2024)
          get_pdf "https://arxiv.org/pdf/2405.07437" \
            "${DATA_DIR}/survey_eval_rag_yu_2024.pdf"

          # 12) Survey: Comprehensive RAG (Gupta et al., 2024) — if this 2024+ id shifts, fallback will error and stop; adjust as needed
          get_pdf "https://arxiv.org/pdf/2410.12837" \
            "${DATA_DIR}/survey_comprehensive_rag_gupta_2024.pdf"


          echo "== Downloading official guides/tutorials as TXT (8) =="

          # 13) LangChain (Python) – RAG Tutorial
          get_doc_as_txt "https://python.langchain.com/docs/tutorials/rag/" \
            "${DATA_DIR}/langchain_rag_tutorial_python.txt"

          # 14) LangChain – QA chat history (useful for conversational RAG)
          get_doc_as_txt "https://python.langchain.com/docs/tutorials/qa_chat_history/" \
            "${DATA_DIR}/langchain_rag_part2_chat_history.txt"

          # 15) Haystack – Get Started
          get_doc_as_txt "https://docs.haystack.deepset.ai/docs/get_started" \
            "${DATA_DIR}/haystack_get_started_rag.txt"

          # 16) Haystack – First RAG pipeline tutorial
          get_doc_as_txt "https://haystack.deepset.ai/tutorials/27_first_rag_pipeline" \
            "${DATA_DIR}/haystack_first_rag_pipeline.txt"

          # 17) LlamaIndex – Introduction to RAG
          get_doc_as_txt "https://docs.llamaindex.ai/en/stable/understanding/rag/" \
            "${DATA_DIR}/llamaindex_intro_rag.txt"

          # 18) LlamaIndex – O’Reilly course cookbooks index (official)
          get_doc_as_txt "https://docs.llamaindex.ai/en/stable/examples/cookbooks/oreilly_course_cookbooks/" \
            "${DATA_DIR}/llamaindex_cookbooks_overview.txt"

          # 19) OpenAI Cookbook – RAG with Elasticsearch
          get_doc_as_txt "https://cookbook.openai.com/examples/vector_databases/elasticsearch/elasticsearch-retrieval-augmented-generation" \
            "${DATA_DIR}/openai_cookbook_rag_elasticsearch.txt"

          # 20) OpenAI Cookbook – Evaluate RAG with LlamaIndex
          get_doc_as_txt "https://cookbook.openai.com/examples/evaluation/evaluate_rag_with_llamaindex" \
            "${DATA_DIR}/openai_cookbook_evaluate_rag_llamaindex.txt"

          echo
          echo "== Downloaded files =="
          ls -lh "${DATA_DIR}"
          SH
          chmod +x download_data.sh

      - name: Run downloader (fetch 20 docs into data/)
        run: ./download_data.sh

      - name: Ingest into store/
        run: |
          python rag.py ingest --data "${DATA_DIR}" --store "${STORE_DIR}"

      - name: Run tests (if present)
        run: |
          python -m pytest -q || echo "No tests or tests failed — continuing"

      - name: Ask question and write answers.json
        run: |
          python batch.py --store "${STORE_DIR}" --q "${QUESTION}" --k "${TOP_K}" --out answers.json
          echo "== answers.json =="
          cat answers.json

      - name: Upload answers artifact
        uses: actions/upload-artifact@v4
        with:
          name: rag-answers
          path: answers.json

      # Publish static dashboard at root (for GitHub Pages)
      - name: Publish static dashboard to root
        run: |
          cp -f pages.index.html index.html
          cp -f pages.app.js app.js
          cp -f pages.style.css style.css
          echo "== root listing =="
          ls -la

      - name: Commit & push (root site + answers.json)
        if: github.ref == 'refs/heads/main'
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add -A
          git commit -m "RAG: download 20 docs + ingest + answer + publish dashboard [skip ci]" || echo "Nothing to commit"
          git push
